name: å¸å®‰ç›‘æ§(ç»ˆæçŒæ‰‹ç‰ˆ)

on:
  schedule:
    - cron: '*/20 * * * *'
  workflow_dispatch: # æ‰‹åŠ¨è§¦å‘

jobs:
  monitor:
    runs-on: ubuntu-latest
    steps:
      - name: å‡†å¤‡ç¯å¢ƒ
        uses: actions/checkout@v2

      - name: å®‰è£… Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'

      - name: å®‰è£…ä¾èµ–
        # æ³¨æ„ï¼šè¿™æ¬¡æˆ‘ä»¬å®‰è£…çš„æ˜¯ ntscraperï¼Œå®ƒæ˜¯ä¸“é—¨çˆ¬æ¨ç‰¹çš„
        run: pip install requests deep-translator ntscraper

      - name: è¿è¡Œç›‘æ§è„šæœ¬
        env:
          PUSH_TOKEN: "d5f7de478314479bba5bce5b4fb1388b"
        run: |
          python -c "
          from ntscraper import Nitter
          import requests
          import os
          import time
          from deep_translator import GoogleTranslator

          token = os.environ['PUSH_TOKEN']
          target_username = 'BinanceWallet' # ä½ çš„ç›®æ ‡è´¦å·

          print('================ å¯åŠ¨ Nitter çŒæ‰‹ ================')
          print(f'æ­£åœ¨æœå¯» {target_username} çš„æœ€æ–°æ¨æ–‡...')
          
          try:
              # åˆå§‹åŒ–çˆ¬è™«ï¼Œè®©å®ƒè‡ªå·±å»å¯»æ‰¾èƒ½ç”¨çš„æœåŠ¡å™¨
              scraper = Nitter(log_level=1)
              
              # æŠ“å–æœ€æ–°çš„ 3 æ¡æ¨æ–‡
              tweets_data = scraper.get_tweets(target_username, mode='user', number=3)
              
              if tweets_data and 'tweets' in tweets_data and len(tweets_data['tweets']) > 0:
                  # æ‹¿åˆ°æœ€æ–°çš„ä¸€æ¡
                  newest = tweets_data['tweets'][0]
                  
                  # æ‰“å°å‡ºæ¥çœ‹çœ‹æŠ“åˆ°äº†ä»€ä¹ˆ
                  print(f'âœ… æŠ“å–æˆåŠŸï¼ID: {newest.get(\"link\", \"æœªçŸ¥\")}')
                  print(f'ğŸ“„ å†…å®¹ç‰‡æ®µ: {newest.get(\"text\", \"\")[:30]}...')
                  
                  # === å¼ºåˆ¶å‘é€é€šçŸ¥ï¼ˆè°ƒè¯•ç”¨ï¼‰===
                  # å¦‚æœä½ æƒ³æ¢å¤æ—¶é—´é™åˆ¶ï¼Œä»¥åå†è¯´ï¼Œå…ˆç¡®ä¿èƒ½æ”¶åˆ°ï¼
                  
                  raw_text = newest.get('text', 'æ— å†…å®¹')
                  link = newest.get('link', 'https://twitter.com/' + target_username)
                  date = newest.get('date', 'æœªçŸ¥æ—¶é—´')
                  
                  # ç¿»è¯‘
                  try:
                      translator = GoogleTranslator(source='auto', target='zh-CN')
                      translated_text = translator.translate(raw_text)
                  except:
                      translated_text = 'ç¿»è¯‘è¶…æ—¶'

                  title = 'ğŸš¨ å¸å®‰é’±åŒ…æ¨æ–‡ (ntscraperç‰ˆ)'
                  content = f'''
                  <b>ã€å‘å¸ƒæ—¶é—´ã€‘</b> {date}<br>
                  <b>ã€ç¿»è¯‘ã€‘</b><br>{translated_text}<br>
                  <br><b>ã€åŸæ–‡ã€‘</b><br>{raw_text}<br>
                  <br>ğŸ‘‰ <a href=\"{link}\">ç‚¹å‡»æŸ¥çœ‹åŸæ–‡</a>
                  '''
                  
                  requests.post('http://www.pushplus.plus/send', json={'token': token, 'title': title, 'content': content, 'template': 'html'})
                  print('âœ… å¾®ä¿¡æ¨é€å·²å‘å‡ºï¼')
                  
              else:
                  print('âŒ æŠ“å–ç»“æœä¸ºç©ºã€‚')
                  print('å¯èƒ½åŸå› ï¼šGitHub çš„ IP æš‚æ—¶è¢«æ‰€æœ‰ Nitter èŠ‚ç‚¹æ‹‰é»‘äº†ã€‚')
                  if tweets_data:
                       print(f'è°ƒè¯•ä¿¡æ¯: {tweets_data}')
                  
          except Exception as e:
              print(f'âŒ è„šæœ¬å‡ºé”™: {e}')
          
          print('================ ç»“æŸ ================')
          "
